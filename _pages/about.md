---
permalink: /

excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- ‚ú® Minimal & Beautiful Quote -->
<!-- <div style="
  max-width: 700px;
  margin: 3em auto 2em auto;
  text-align: center;
  font-family: 'Georgia', serif;
  color: #444;
  line-height: 1.6;
  position: relative;
">

  <p style="font-size: 1.4em; font-style: italic; margin: 0.2em 0 0.5em;">
    Colorless <span style="color: #228B22;">green</span> ideas sleep <span style="color: #E25822;">furiously</span>.
  </p>

  <p style="font-size: 0.95em; font-weight: bold; color: #777; margin-top: 0.5em;">
    ‚Äî Noam Chomsky
  </p>
</div> -->

<!-- üß† Title as heading --> 
<!-- <h1 style="text-align: center; margin-top: 2em;">About Me</h1> -->

About Me
---

I am currently a **Ph.D. candidate in Computer Science** at **UIUC**, advised by [Dr. Ismini Lourentzou](https://isminoula.github.io/). I began my doctoral studies at Virginia Tech, where I had also worked under [Dr. Kurt Luther](https://crowd.cs.vt.edu/kurt-luther/). Prior to my Ph.D., I earned an M.S. in Computer Science from **Georgetown University** and a B.A. in Computer Science (Linguistics concentration) from **University of Minnesota, Twin Cities.**


My research centers on **reasoning in 3D and embodied settings**, grounded in a broader foundation of **natural language processing and multimodal learning**.
I study how structured representations - linguistic, spatial, and geometric ‚Äî can be integrated to enable machines to reason about the world in a grounded, interpretable, and generative way.

My recent work explores:

- **Collaborative reasoning frameworks** that unify language and 3D generation  
- **Part-level 3D generation and articulation** for modeling structured objects  
- **Uncertainty-aware embodied agents** that adapt reasoning and planning in dynamic environments

Across these directions, I aim to build language-enabled systems that do not merely predict tokens or pixels, but instead reason over **structure, parts, space, and action**. My work draws inspiration from **theoretical linguistics, 3D representation learning, and multimodal world modeling** to develop agents that can understand, construct, and interact with complex 3D worlds.

Beyond my academic work, I co-founded <a href="https://tianjiao-yu.github.io/eternl_ai/" style="text-decoration: none;"><span style="background: linear-gradient(90deg, #ff4fd8, #3b82f6); -webkit-background-clip: text; background-clip: text; color: transparent; font-weight: 800;">Eternl.AI</span></a>, where I architect AI infrastructure for embodied intelligence in interactive gaming. My work spans **agentic AI** (LLMs + RL for goal-directed decision-making), **long-horizon personalization** (RAG + PEFT for consistent interactions), and **3D-world generation** (object/character generation and scene synthesis for coherent, interactive environments), translating embodied reasoning and structured generation research into production-scale systems.
<br>
<br>

Publications
---
‚≠ê‚≠ê‚≠ê **DreamPartGen: 3D Generation with Part‚ÄëLevel Text Guidance through Collaborative Part‚ÄëLatent Denoising**, under review, 2025 <br>
**Tianjiao Yu**, Muntasir Wahed, Jerry Yuyang Xiong, Xinzhuo Li, Yifan Shen, Ying Shen, Ismini Lourentzou. <br>
‚≠ê‚≠ê‚≠ê **CoRe3D: Collaborative Reasoning as a Foundation for 3D Intelligence**, Arxiv, 2025 <br>
**Tianjiao Yu**, Xinzhuo Li, Yifan Shen, Yuanzhe Liu, Ismini Lourentzou.
[Project Page](https://plan-lab.github.io/projects/core3d/) ¬∑ [Paper Link](https://arxiv.org/abs/2512.12768) <br>
‚≠ê‚≠ê‚≠ê **Part¬≤GS: Part-aware Modeling of articulated Objects using 3D Gaussian Splatting**, Arxiv, 2025 <br>
**Tianjiao Yu**, Vedant Shah, Muntasir Wahed, Ying Shen, Kiet A. Nguyen, Ismini Lourentzou.
[Project Page](https://plan-lab.github.io/projects/part2gs/) ¬∑ [Paper Link](https://arxiv.org/pdf/2506.17212v1) <br>
‚≠ê‚≠ê‚≠ê **Uncertainty in Action: Confidence Elicitation in Embodied Agents**, Arxiv, 2024 <br>
**Tianjiao Yu**, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Sunil Juvekar, Tal August, Ismini Lourentzou. 
[Project Page](https://plan-lab.github.io/projects/ece/) ¬∑ [Paper Link](https://arxiv.org/pdf/2503.10628) <br>
‚≠ê **MOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?**, EMNLP, 2025 <br>
Muntasir Wahed, Xiaona Zhou, Kiet A Nguyen, **Tianjiao Yu**, Nirav Diwan, Gang Wang, Dilek Hakkani-T√ºr, Ismini Lourentzou.
[Paper Link](https://arxiv.org/abs/2507.19598) <br>
‚≠ê **PurpCode: Reasoning for Safer Code Generation**, Arxiv, 2025 <br>
Jiawei Liu, Nirav Diwan, Zhe Wang, Haoyu Zhai, Xiaona Zhou, Kiet A Nguyen, **Tianjiao Yu**, Muntasir Wahed, Yinlin Deng, Hadjer Benkraouda, Yuxiang Wei, Lingming Zhang, Ismini Lourentzou, Gang Wang.
[Paper Link](https://arxiv.org/abs/2507.19060) <br>
‚≠ê **CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language Models**, CVPR, 2025 <br>
Kiet A Nguyen, Adheesh Juvekar, **Tianjiao Yu**, Muntasir Wahed, Ismini Lourentzou.
[Project Page](https://plan-lab.github.io/projects/calico/) ¬∑ [Paper Link](https://arxiv.org/pdf/2412.19331) <br>
‚≠ê **PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation**, Arxiv, 2024 <br>
Muntasir Wahed, Kiet A Nguyen, Adheesh Sunil Juvekar, Xinzhuo Li, Xiaona Zhou, Vedant Shah, **Tianjiao Yu**, Pinar Yanardag, Ismini Lourentzou.
[Project Page](https://plan-lab.github.io/projects/prima/) ¬∑ [Paper Link](https://arxiv.org/pdf/2412.15209) <br>
‚≠ê‚≠ê‚≠ê **Sedition Hunters: A Quantitative Study of the Crowdsourced Investigation into the 2021 US Capitol Attack**, Proceedings of the ACM Web Conference 2023 <br>
**Tianjiao Yu**, Sukrit Venkatagiri, Ismini Lourentzou, Kurt Luther. 
[Paper Link](https://dl.acm.org/doi/pdf/10.1145/3543507.3583514) <br>
‚≠ê **Sedition Hunters: Countering Extremism through Collective Action**, CSCW 2021 Workshop on Addressing Challenges and Opportunities in Online Extremism Research: An Interdisciplinary Perspective <br>
Sukrit Venkatagiri, **Tianjiao Yu**, Vikram Mohanty, Kurt Luther.
[Paper Link](https://par.nsf.gov/servlets/purl/10315695) <br>
‚≠ê **FARM: Fine‚ÄêGrained Alignment for Cross‚ÄêModal Recipe Retrieval**, Proceedings of the IEEE/CVF Winter Conference
on Applications of Computer Vision. 2024. <br>
Muntasir Wahed, Xiaona Zhou,**Tianjiao Yu**, Ismini Lourentzou.
[Paper Link](https://openaccess.thecvf.com/content/WACV2024/html/Wahed_Fine-Grained_Alignment_for_Cross-Modal_Recipe_Retrieval_WACV_2024_paper.html) <br>
‚≠ê **PLAB‚ÄêBot: Contextualized & Knowledge‚Äêgrounded Multimodal Taskbot**, In Alexa Prize TaskBot Challenge 2 Proceedings, 2023. <br>
Afrina Tabassum, Muntasir Wahed, **Tianjiao Yu**, Amarachi B. Mbakwe, Makanjuola Ogunleye, and Ismini Lourentzou.
[Paper Link](https://www.amazon.science/alexa-prize/proceedings/plan-bot-contextualized-and-knowledge-grounded-multimodal-taskbot) <br>


<!-- {% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %}
 -->
