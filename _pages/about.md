---
permalink: /

excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- ✨ Minimal & Beautiful Quote -->
<div style="
  max-width: 700px;
  margin: 3em auto 2em auto;
  text-align: center;
  font-family: 'Georgia', serif;
  color: #444;
  line-height: 1.6;
  position: relative;
">

  <p style="font-size: 1.4em; font-style: italic; margin: 0.2em 0 0.5em;">
    Colorless <span style="color: #228B22;">green</span> ideas sleep <span style="color: #E25822;">furiously</span>.
  </p>

  <p style="font-size: 0.95em; font-weight: bold; color: #777; margin-top: 0.5em;">
    — Noam Chomsky
  </p>
</div>

<!-- 🧠 Title as heading --> 
<!-- <h1 style="text-align: center; margin-top: 2em;">About Me</h1> -->



I am currently a **Ph.D. candidate in Computer Science** at the **UIUC**, advised by [Dr. Ismini Lourentzou](https://isminoula.github.io/). I began my doctoral studies at Virginia Tech, where I had also worked under [Dr. Kurt Luther](https://crowd.cs.vt.edu/kurt-luther/). Prior to my Ph.D., I earned an M.S. in Computer Science from **Georgetown University** and a B.A. in Computer Science (Linguistics concentration) from the **University of Minnesota, Twin Cities.**

My research lies at the intersection of **natural language processing, multimodal learning**, and **embodied AI**. I am particularly interested in building language-enabled agents that can reason, act, and communicate within dynamic, interactive environments. My work explores how language understanding can be grounded in perception and action, enabling machines to navigate and adapt to the complexities of the real world. During my academic journey, I have had the opportunity to work on various interdisciplinary projects that combine **theoretical linguistics**, **crowdsourced intelligence**, and **social analysis**.

<br>
<br>

Publications
---
📄 **Part²GS: Part-aware Modeling of articulated Objects using 3D Gaussian Splatting**, Arxiv, 2025 <br>
**Tianjiao Yu**, Vedant Shah, Muntasir Wahed, Ying Shen, Kiet A. Nguyen, Ismini Lourentzou
[Project Page](https://plan-lab.github.io/projects/part2gs/) · [Paper Link](https://arxiv.org/pdf/2506.17212v1) <br>
📄 **Uncertainty in Action: Confidence Elicitation in Embodied Agents**, Arxiv, 2024 <br>
**Tianjiao Yu**, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Sunil Juvekar, Tal August, Ismini Lourentzou 
[Project Page](https://plan-lab.github.io/projects/ece/) · [Paper Link](https://arxiv.org/pdf/2503.10628) <br>
📄 **MOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?**, Arxiv, 2025 <br>
Muntasir Wahed, Xiaona Zhou, Kiet A Nguyen, **Tianjiao Yu**, Nirav Diwan, Gang Wang, Dilek Hakkani-Tür, Ismini Lourentzou 
[Paper Link](https://arxiv.org/abs/2507.19598) <br>
📄 **PurpCode: Reasoning for Safer Code Generation**, Arxiv, 2025 <br>
Jiawei Liu, Nirav Diwan, Zhe Wang, Haoyu Zhai, Xiaona Zhou, Kiet A Nguyen, **Tianjiao Yu**, Muntasir Wahed, Yinlin Deng, Hadjer Benkraouda, Yuxiang Wei, Lingming Zhang, Ismini Lourentzou, Gang Wang
[Paper Link](https://arxiv.org/abs/2507.19060) <br>
📄 **CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language Models**, CVPR, 2025 <br>
Kiet A Nguyen, Adheesh Juvekar, **Tianjiao Yu**, Muntasir Wahed, Ismini Lourentzou
[Project Page](https://plan-lab.github.io/projects/calico/) · [Paper Link](https://arxiv.org/pdf/2412.19331) <br>
📄 **PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation**, Arxiv, 2024 <br>
Muntasir Wahed, Kiet A Nguyen, Adheesh Sunil Juvekar, Xinzhuo Li, Xiaona Zhou, Vedant Shah, **Tianjiao Yu**, Pinar Yanardag, Ismini Lourentzou
[Project Page](https://plan-lab.github.io/projects/prima/) · [Paper Link](https://arxiv.org/pdf/2412.15209) <br>
📄 **Sedition Hunters: Countering Extremism through Collective Action**, CSCW 2021 Workshop on Addressing Challenges and Opportunities in Online Extremism Research: An Interdisciplinary Perspective <br>
Sukrit Venkatagiri, **Tianjiao Yu**, Vikram Mohanty, Kurt Luther
[Paper Link](https://par.nsf.gov/servlets/purl/10315695) <br>
📄 **Sedition Hunters: A Quantitative Study of the Crowdsourced Investigation into the 2021 US Capitol Attack**, Proceedings of the ACM Web Conference 2023 <br>
**Tianjiao Yu**, Sukrit Venkatagiri, Ismini Lourentzou, Kurt Luther 
[Paper Link](https://dl.acm.org/doi/pdf/10.1145/3543507.3583514) <br>
📄 **FARM: Fine‐Grained Alignment for Cross‐Modal Recipe Retrieval**, Proceedings of the IEEE/CVF Winter Conference
on Applications of Computer Vision. 2024. <br>
Muntasir Wahed, Xiaona Zhou,**Tianjiao Yu**, Ismini Lourentzou
[Paper Link](https://openaccess.thecvf.com/content/WACV2024/html/Wahed_Fine-Grained_Alignment_for_Cross-Modal_Recipe_Retrieval_WACV_2024_paper.html) <br>
📄 **PLAB‐Bot: Contextualized & Knowledge‐grounded Multimodal Taskbot**, In Alexa Prize TaskBot Challenge 2 Proceedings, 2023. <br>
Afrina Tabassum, Muntasir Wahed, **Tianjiao Yu**, Amarachi B. Mbakwe, Makanjuola Ogunleye, and Ismini Lourentzou
[Paper Link](https://www.amazon.science/alexa-prize/proceedings/plan-bot-contextualized-and-knowledge-grounded-multimodal-taskbot) <br>
📄 **The Design of Electronic Medical Records System Using Skip-gram Algorithm**, Network Modeling Analysis in Health Informatics and Bioinformatics <br>
**Tianjiao Yu** 
[Paper Link](https://link.springer.com/article/10.1007/s13721-020-00281-4) <br>

<!-- {% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %}
 -->
